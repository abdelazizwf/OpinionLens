stages:
  preprocess_data:
    cmd: mkdir -p ./data/preprocessed && mkdir -p ./data/eval_data && uv run preprocess_data
    deps:
      - src/opinionlens/preprocessing/scripts/preprocess_data.py
      - src/opinionlens/preprocessing/clean.py
      - src/opinionlens/preprocessing/tokenize.py
      - data/raw/IMDB Dataset/
      - data/raw/Amazon Food Reviews/
    params:
      - preprocessing.data_splits
    outs:
      - data/preprocessed/
      - data/eval_data/

  vectorize_data:
    cmd: mkdir -p ./data/vectorized && uv run vectorize_data
    deps:
      - src/opinionlens/preprocessing/scripts/vectorize_data.py
      - src/opinionlens/preprocessing/vectorize.py
      - data/preprocessed/
      - data/eval_data/
    outs:
      - data/vectorized/

  run_baselines:
    cmd: uv run baselines
    deps:
      - data/preprocessed/
    always_changed: true

  train_sklearn:
    cmd: uv run train_sklearn
    deps:
      - data/vectorized/
    always_changed: true

  tune_sklearn:
    cmd: uv run tune_sklearn
    deps:
      - data/vectorized/
    always_changed: true

  run_evals:
    cmd: uv run evals
    deps:
      - data/eval_data/
    always_changed: true
