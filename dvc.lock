schema: '2.0'
stages:
  preprocess_data:
    cmd: mkdir -p ./data/preprocessed && mkdir -p ./data/eval_data && uv run
      preprocess_data
    deps:
    - path: data/raw/Amazon Food Reviews/
      hash: md5
      md5: 09c682d2842ec908860aedae0ba600cc.dir
      size: 300904694
      nfiles: 1
    - path: data/raw/IMDB Dataset/
      hash: md5
      md5: 186740f5cbef806685fcd27585e6f852.dir
      size: 66212309
      nfiles: 1
    - path: src/opinionlens/preprocessing/clean.py
      hash: md5
      md5: 6c3c121a895a63672af8e0f685d9fc19
      size: 272
    - path: src/opinionlens/preprocessing/scripts/preprocess_data.py
      hash: md5
      md5: e46bc4c67536a1517e6f4131c1e31d90
      size: 2674
    - path: src/opinionlens/preprocessing/tokenize.py
      hash: md5
      md5: fce993fc09013a0e45c08fa7bcc710ec
      size: 245
    params:
      params.yaml:
        preprocessing.data_splits:
        - 0.8
        - 0.1
        - 0.1
    outs:
    - path: data/eval_data/
      hash: md5
      md5: ece7d9d96b286d68359f5d3bec77cff0.dir
      size: 72615464
      nfiles: 5
    - path: data/preprocessed/
      hash: md5
      md5: d4aafacd50abeb3287d15008cc08fd34.dir
      size: 300513170
      nfiles: 6
  vectorize_data:
    cmd: mkdir -p ./data/vectorized && uv run vectorize_data
    deps:
    - path: data/eval_data/
      hash: md5
      md5: ece7d9d96b286d68359f5d3bec77cff0.dir
      size: 72615464
      nfiles: 5
    - path: data/preprocessed/
      hash: md5
      md5: d4aafacd50abeb3287d15008cc08fd34.dir
      size: 300513170
      nfiles: 6
    - path: src/opinionlens/preprocessing/scripts/vectorize_data.py
      hash: md5
      md5: e95728da903fbd5aa99f023fd79d055b
      size: 1788
    - path: src/opinionlens/preprocessing/vectorize.py
      hash: md5
      md5: 4717282105da1a10c51a0ad454ef6a29
      size: 942
    outs:
    - path: data/vectorized/
      hash: md5
      md5: c5034cfb7bea5a1d3632a958c1812298.dir
      size: 453673476
      nfiles: 6
  run_baselines:
    cmd: uv run baselines
    deps:
    - path: data/preprocessed/
      hash: md5
      md5: e273f67071cf73efb3840c23b5036965.dir
      size: 300513170
      nfiles: 6
  train_sklearn:
    cmd: uv run train_sklearn
    deps:
    - path: data/vectorized/
      hash: md5
      md5: c5034cfb7bea5a1d3632a958c1812298.dir
      size: 453673476
      nfiles: 6
  tune_sklearn:
    cmd: uv run tune_sklearn
    deps:
    - path: data/vectorized/
      hash: md5
      md5: c5034cfb7bea5a1d3632a958c1812298.dir
      size: 453673476
      nfiles: 6
  run_evals:
    cmd: uv run evals
    deps:
    - path: data/eval_data/
      hash: md5
      md5: ece7d9d96b286d68359f5d3bec77cff0.dir
      size: 72615464
      nfiles: 5
